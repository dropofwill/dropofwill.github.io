---
title: Response to Pasquale's The Black Box Society
date: 2015-11-03 02:15 UTC
tags: Review, FOSS
published: false

---

<!--
As part of your notebook entries, I would like you to write up a short response piece: a couple of pages (say ~700 words for those of you counting) on this topic. As we have seen, the hidden hand of the market largely exists within black box activities at a techno-social level. After reading chapters from Pasquale's recent book, I would like you to reflect on how to recognize and navigate the effect of having your personal data (and, by extension, personal lives) harvested and put to use in a variety of ways.

In various ways, explicit and tacit, we negotiate these surroundings, these data structures which increasingly apprehend and apportion our social relations.

Reflect on how to recognize the effect of having personal data/live gathered in the ways it is.

-->

I am especially torn when it comes to the issue of data collection, because even as a strong proponent of privacy (e.g. I don't even 'google' in lieu of open source alternatives, see: searx), I am also a data science 'geek'. I like to collect and analyze my own data (sleep cycles, music listening patterns, browser history, etc.) as well as data I have scraped from the internet, downloaded from public datasets, or collected in an academic research setting. Data collection and analysis, especially when released to the public domain, has led to a number of tangible benefits across many fields. This internal conflict really boils down to how can radical openness be paired with the seemingly opposite goal of complete privacy and control.

Over and over again throughout Pasquale's book we see issues of proprietary data collection carried out for the interests of corporate, public, and the ever increasing public-corporate blend. It seems almost obvious at this point that these sorts of institutions do not have out best interests in mind. But then again how is this any different than me collecting speech data, data that will not be released to the public domain in order to respect the *privacy* of those involved in the study?

I think this, like most socio-political issues, comes down to the concept of power. Who has power over the data? When I collect data about my sleep cycles I have complete control over my own data. However, when Google is building its advertisement profile for me I have no public say in the matter, no opt out recourse available. Worse this profile is not even available for me to understand in any material way. But what about my speech research? Yes, the subjects signed off that their data could be used and used for a particular purpose, the results of which are published in a publicly available proceedings (an advantage of the openness of the speech processing community), but at the same time it is very much a closed system, where these subjects put their trust in my lab.

Because of this I am interested in coming up with new distributed machine learning algorithms that allow the user to garner the benefits of a training set of countless other users, while never letting their own data leave their device. While nothing like this has been really even been theorized yet, advances in the cryptography like the Bitcoin block chain make these sorts of wild ideas seem more feasible. The unfortunate part is that nobody seems to be concerned about this, since it is more advantageous from a corporate perspective to have a central body of knowledge, than a distributed system where they no nothing.

